{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Clustering Models\n",
    "\n",
    "In this assignment, you will implement the K-means method and apply it to image compression. Then you will use the Gaussian Mixture Models from the scikit-learn library and select the number of clusters K using the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1) Implement the K-means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Process of K-means:\n",
    "    1. Select the desired amount of clusters, K.\n",
    "    2. Randomly select K distinct data points; these are the initial clusters.\n",
    "    3. Measure the distance between the first data point and all the K initial clusters. For 2D, euclidian distance.\n",
    "    4. Assign the first point to its nearest cluster. Do the same thing for all the remaining points.\n",
    "    5. Calculate the mean of each cluster.\n",
    "    6. Then we repeat the process, but this time with the mean values as the clusters (cluster points).\n",
    "    The result of the clusters produced by this method is measured by the variation within the clusters.\n",
    "    The model cannot \"see\" the clusters, it can only determine weather the clusters are good or not with \n",
    "    measuring the variation within and then sum the variation. \n",
    "    Since the initial points are chosen at random, it is good practice to repeat the above method \n",
    "    multiple times, with different randomised initial point, and for each result\n",
    "    measure the variation within each cluster and determine which one produced the best clusters \n",
    "    by comparing them with each other.  \n",
    "\n",
    "    Pick K by finding the \"elbow\" in an \"eblow-plot\". The \"elbow-plot\" is a plot of the reduction\n",
    "    in variance per value of K.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def kmeans(x, K: int, n_init: int):   \n",
    "    # x: input data     \n",
    "    # K: number of centroids\n",
    "    # n_init: the number of initial guesses for the centroids\n",
    "    # centroids: contains the centers of the clusters\n",
    "    # labels: contains the cluster index for each data point \n",
    "    return centroids, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2) Apply the K-means algorithm to compress images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3) Use AIC and BIC to choose K for Gaussian Mixture Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
